{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9edd488a-4523-4209-9ef7-f1e1f0fd6c24",
   "metadata": {},
   "source": [
    "## web Scrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810620df-191b-47ca-917a-7011b1c548f1",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2332fd4a-cf96-4ccb-b509-2c771a4809f0",
   "metadata": {},
   "source": [
    "### What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
    "#### Web scraping is an automatic method to obtain large amounts of data from websites. Most of this data is unstructured data in an HTML format which is then converted into structured data in a spreadsheet or a database so that it can be used in various applications.\n",
    "#### Web-scraping provides one of the great tools to automate most of the things a human does while browsing. So the best use of Web Scraping to scrape the website for large amount data.\n",
    "#### Web Scraping has multiple applications across various industries like Price Monitoring, Market Research, Sentiment Analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a135d8-a244-467b-b3da-295e5297e1d7",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfa38ec-20ba-4db9-b690-114ca83c4ef6",
   "metadata": {},
   "source": [
    "### What are the different methods used for Web Scraping?\n",
    "#### There are many different ways to perform web scraping to obtain data from websites. These include using online services, particular APIâ€™s or even creating our code for web scraping from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffdd6d6-6df6-44ad-a790-6e7f3b654862",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cb2a4a-ef1b-4001-8325-948a0f6c219c",
   "metadata": {},
   "source": [
    "### What is Beautiful Soup? Why is it used?\n",
    "#### Beautiful Soup is a Python library for pulling data out of HTML and XML files. It works with the parser to provide idiomatic ways of navigating, searching, and modifying the parse tree. It transforms a complex HTML document into a tree of Python objects. It also automatically converts the document to Unicode.\n",
    "#### Beautiful Soup is a Python library that is used for web scraping purposes to pull the data out of HTML and XML files. It creates a parse tree from page source code that can be used to extract data in a hierarchical and more readable manner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4d1614-f1ab-4ab8-9eb6-e9d468e10305",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e65af97-9322-4659-9158-78ad0cdf9c06",
   "metadata": {},
   "source": [
    "### Why is flask used in this Web Scraping project?\n",
    "#### Flask is a lightweight framework to build websites. We'll use this to parse our collected data and display it as HTML in a new HTML file. The requests module allows us to send http requests to the website we want to scrape."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fab22c-9c10-4e76-8b29-912c4dd29376",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074ac666-74e8-41d7-a3bc-f13d1f9f9bb6",
   "metadata": {},
   "source": [
    "### Write the names of AWS services used in this project. Also, explain the use of each service.\n",
    "#### Code Pipeline and Elastic BeanStalk\n",
    "#### Code Pipeline: AWS CodePipeline is a continuous delivery service one can use to model, visualize, and automate the steps required to release a software. We can quickly model and configure the different stages of a software release process. CodePipeline automates the steps required to release our software changes continuously.\n",
    "#### Elastic BeanStalk: AWS Elastic Beanstalk is an AWS managed service for web applications. Elastic beanstalk is a pre-configured EC2 server that can directly take up our application code and environment configurations and use it to automatically provision and deploy the required resources within AWS to run the web application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4931c79f-b262-4f4a-8625-a054320070a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8124d997-024e-4a13-b1bf-23e60b023a91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
